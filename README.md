# ğŸ›¡ï¸ Social Media & Abuse Detection System

<div align="center">

![Version](https://img.shields.io/badge/version-2.0.0-6366f1?style=for-the-badge)
![Python](https://img.shields.io/badge/Python-3.10+-3776AB?style=for-the-badge&logo=python&logoColor=white)
![FastAPI](https://img.shields.io/badge/FastAPI-0.110+-009688?style=for-the-badge&logo=fastapi&logoColor=white)
![React](https://img.shields.io/badge/React-18+-61DAFB?style=for-the-badge&logo=react&logoColor=black)
![License](https://img.shields.io/badge/license-MIT-10b981?style=for-the-badge)

**Real-time AI-powered content moderation for social media platforms.**  
Detects threats, hate speech, insults, obscenity & sarcasm with contextual intelligence.

[Features](#-features) â€¢ [Architecture](#-architecture) â€¢ [Setup](#-setup) â€¢ [API Reference](#-api-reference) â€¢ [Demo](#-demo)

</div>

---

## ğŸš€ Features

| Feature | Description |
|---|---|
| ğŸ”´ **Real-time Analysis** | Debounced live inference as you type â€” results in <100ms |
| ğŸ“‚ **File Upload** | Batch analyze `.txt`, `.csv`, `.json` files (up to 500 rows, parallel inference) |
| ğŸŒ **URL Analyzer** | Fetch & scan any public web page for toxic content |
| ğŸ“Š **Visual Charts** | Area chart (risk history), radar chart (category distribution) |
| âš™ï¸ **Sensitivity Control** | Adjustable detection threshold (High / Balanced / Strict) |
| ğŸ”´ **Live Stream Sim** | Simulated real-time social media chat moderation |
| ğŸ“‹ **Session Log** | Full exportable CSV log of all analyzed messages |
| ğŸ¯ **Word Highlighting** | Token-level attention mapping â€” highlights toxic words |
| ğŸŒ™ **Dark Mode UI** | Glassmorphism design with neon glows and smooth animations |

---

## ğŸ§  Detection Model

The model uses a **multi-layer heuristic NLP pipeline**:

### 5 Toxicity Categories
- âš ï¸ **Threat** â€” Violence, assault, murder, kidnapping, doxxing
- ğŸš« **Hate Speech** â€” Racism, homophobia, antisemitism, supremacism
- ğŸ’¢ **Insult** â€” Personal attacks, body shaming, intelligence attacks
- ğŸ¤¬ **Obscenity** â€” Profanity, explicit language
- ğŸ˜ **Sarcasm** â€” Passive-aggressive/ironic content

### Detection Layers
```
Layer 1 â†’ Keyword matching        (250+ toxic keywords, scored by category)
Layer 2 â†’ Proximity detection     (derogatory word near person noun â†’ amplify)
Layer 3 â†’ Multi-word phrases      (60+ exact toxic phrase matches)
Layer 4 â†’ Sarcasm patterns        (contextual sarcasm keywords)
Layer 5 â†’ Negation dampening      (not/never/don't before toxic word â†’ reduce score)
Layer 6 â†’ Context modifiers       (gaming/medical/news context â†’ reduce by 55%)
Layer 7 â†’ Safe word whitelist     (80+ safe words never flagged)
```

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FRONTEND (React + Vite)               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Text Input  â”‚ â”‚File Upload â”‚ â”‚   URL Analyzer   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                         â”‚ HTTP / REST API               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  BACKEND (FastAPI + Python)               â”‚
â”‚                                                          â”‚
â”‚   POST /analyze        â†’ Single text analysis            â”‚
â”‚   POST /analyze-bulk   â†’ Parallel batch (asyncio.gather) â”‚
â”‚   POST /analyze-file   â†’ Upload + parse txt/csv/json     â”‚
â”‚   POST /analyze-url    â†’ Fetch web page + strip HTML     â”‚
â”‚   GET  /health         â†’ Status check                    â”‚
â”‚                                                          â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚              ToxicityModel v2                    â”‚   â”‚
â”‚   â”‚  Keywords | Phrases | Proximity | Context-Aware  â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¦ Tech Stack

### Backend
- **FastAPI** â€” High-performance async REST API
- **Python 3.10+** â€” Async/await native
- **httpx** â€” Async HTTP client for URL fetching
- **Uvicorn** â€” ASGI server with hot-reload

### Frontend
- **React 18** + **Vite** â€” Fast modern SPA
- **Tailwind CSS v4** â€” Utility-first styling
- **Framer Motion** â€” Smooth animations
- **Recharts** â€” Area + radar charts
- **Lucide React** â€” Icon system

---

## ğŸ”§ Setup

### Prerequisites
- Python 3.10+
- Node.js 18+

### 1. Backend
```bash
cd toxicity-app/backend
pip install -r requirements.txt
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

### 2. Frontend
```bash
cd toxicity-app/frontend
npm install
npm run dev -- --force
```

### 3. Open
```
Frontend â†’ http://localhost:5173
API Docs â†’ http://localhost:8000/docs
```

---

## ğŸ“¡ API Reference

### `POST /analyze`
Analyze a single text message.

```json
// Request
{ "text": "You are such a waste of space", "threshold": 0.3 }

// Response
{
  "risk_score": 88.0,
  "labels": { "Threat": 0.03, "Hate Speech": 0.09, "Insult": 0.88, "Obscenity": 0.03, "Sarcasm": 0.03 },
  "highlights": ["waste"],
  "processing_time_ms": 52.4
}
```

### `POST /analyze-bulk`
Batch analyze up to 500 texts in parallel.

```json
// Request
{ "texts": ["text1", "text2", "..."], "threshold": 0.3 }

// Response
{
  "results": [...],
  "total": 42, "toxic_count": 8, "safe_count": 34,
  "avg_risk_score": 23.5, "processing_time_ms": 210.0
}
```

### `POST /analyze-file`
Upload a `.txt`, `.csv`, or `.json` file.

```
multipart/form-data: file=<binary>, threshold=0.3
```

### `POST /analyze-url`
Fetch and analyze a web page.

```json
// Request
{ "url": "https://en.wikipedia.org/wiki/Hate_speech", "threshold": 0.3 }
```

---

## ğŸ“Š Performance

| Metric | Value |
|---|---|
| Single inference | ~50ms |
| Bulk 100 texts | ~200ms (parallel) |
| URL fetch + analysis | ~1â€“3s |
| Frontend bundle size | < 500KB |
| Memory usage | < 100MB |

---

## ğŸ¯ Use Cases

1. **Social Media Platforms** â€” Auto-moderate user comments in real-time
2. **Customer Support** â€” Flag aggressive/threatening support tickets
3. **Gaming** â€” Chat moderation in multiplayer games
4. **Content Review** â€” Pre-publication content screening
5. **Research** â€” Batch analyze datasets for toxicity patterns

---

## ğŸ‘¥ Team

Built for **Hackathon 2026** by Team Shield

---

## ğŸ“„ License

MIT License â€” free to use, modify, and distribute.
